/**
 * Unified Groq AI Service
 * Ğ’ÑĞµ AI Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‡ĞµÑ€ĞµĞ· Groq API (ĞºÑ€Ğ¾Ğ¼Ğµ Assistants)
 * âœ… Chat - Llama 3.3 70B (93% Ğ´ĞµÑˆĞµĞ²Ğ»Ğµ OpenAI)
 * âœ… Vision - Llama 4 Scout (96% Ğ´ĞµÑˆĞµĞ²Ğ»Ğµ OpenAI)
 * âœ… Whisper - ÑƒĞ¶Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ (97% Ğ´ĞµÑˆĞµĞ²Ğ»Ğµ OpenAI)
 */

import OpenAI from 'openai';
import { toFile } from 'openai/uploads';
import sharp from 'sharp';

// âœ… Groq client (OpenAI-ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ñ‹Ğ¹)
const groq = new OpenAI({
  apiKey: process.env.GROQ_API_KEY || '',
  baseURL: 'https://api.groq.com/openai/v1'
});

// âœ… Fallback OpenAI (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ Assistants)
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || ''
});

interface ChatResponse {
  message: string;
  usage?: {
    input_tokens: number;
    output_tokens: number;
    cost_usd: number;
  };
}

interface VisionResponse {
  analysis: string;
  usage?: {
    input_tokens: number;
    output_tokens: number;
    cost_usd: number;
  };
}

/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * CHAT OPERATIONS (Groq Llama 3.3 70B)
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */

export async function processChat(
  message: string,
  conversationHistory?: Array<{ role: 'user' | 'assistant' | 'system'; content: string }>,
  systemPrompt?: string
): Promise<ChatResponse> {
  try {
    const messages: OpenAI.Chat.ChatCompletionMessageParam[] = [
      {
        role: 'system',
        content: systemPrompt || `Ğ¢Ñ‹ AI-ĞºÑƒÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ñ‹. 
ĞŸĞ¾Ğ¼Ğ¾Ğ³Ğ°Ğ¹ ÑÑ‚ÑƒĞ´ĞµĞ½Ñ‚Ğ°Ğ¼ Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼, Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹, Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°Ğ¹ Ñ€ĞµÑÑƒÑ€ÑÑ‹.
Ğ‘ÑƒĞ´ÑŒ Ğ´Ñ€ÑƒĞ¶ĞµĞ»ÑĞ±Ğ½Ñ‹Ğ¼, Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼ Ğ¸ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ÑÑ‰Ğ¸Ğ¼ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.`
      },
      ...(conversationHistory || []),
      { role: 'user', content: message }
    ];

    console.log('ğŸ’¬ [Groq Chat] ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°...');
    
    const response = await groq.chat.completions.create({
      model: 'meta-llama/llama-3.3-70b-versatile', // Ğ›ÑƒÑ‡ÑˆĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ñ€ÑƒÑÑĞºĞ¾Ğ³Ğ¾
      messages,
      max_tokens: 1500,
      temperature: 0.7,
    });

    const content = response.choices[0].message.content || '';
    
    // Ğ Ğ°ÑÑÑ‡Ñ‘Ñ‚ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
    const usage = response.usage ? {
      input_tokens: response.usage.prompt_tokens,
      output_tokens: response.usage.completion_tokens,
      cost_usd: calculateCost('chat', response.usage.prompt_tokens, response.usage.completion_tokens)
    } : undefined;

    console.log(`âœ… [Groq Chat] ĞÑ‚Ğ²ĞµÑ‚ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½: ${content.length} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²`);
    if (usage) {
      console.log(`ğŸ’° [Groq Chat] Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: $${usage.cost_usd.toFixed(6)} (${usage.input_tokens}+${usage.output_tokens} Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²)`);
    }

    return { message: content, usage };
  } catch (error: any) {
    console.error('âŒ [Groq Chat] ĞÑˆĞ¸Ğ±ĞºĞ°:', error.message);
    throw new Error(`Groq Chat failed: ${error.message}`);
  }
}

/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * VISION OPERATIONS (Groq Llama 4 Scout)
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */

export async function analyzeImage(
  imageBuffer: Buffer,
  question: string,
  imageMimeType: string = 'image/png'
): Promise<VisionResponse> {
  try {
    console.log('ğŸ–¼ï¸ [Groq Vision] ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ...');
    
    // ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ (Groq Ğ»Ğ¸Ğ¼Ğ¸Ñ‚: 4MB base64)
    const optimizedImage = await optimizeImageForVision(imageBuffer);
    const base64Image = optimizedImage.toString('base64');

    const response = await groq.chat.completions.create({
      model: 'meta-llama/llama-4-scout-17b-16e-instruct', // Ğ‘Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ğ¸ Ğ´ĞµÑˆÑ‘Ğ²Ğ°Ñ
      messages: [{
        role: 'user',
        content: [
          { type: 'text', text: question },
          {
            type: 'image_url',
            image_url: { url: `data:${imageMimeType};base64,${base64Image}` }
          }
        ]
      }],
      max_tokens: 1500,
    });

    const content = response.choices[0].message.content || '';
    
    const usage = response.usage ? {
      input_tokens: response.usage.prompt_tokens,
      output_tokens: response.usage.completion_tokens,
      cost_usd: calculateCost('vision', response.usage.prompt_tokens, response.usage.completion_tokens)
    } : undefined;

    console.log(`âœ… [Groq Vision] ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½: ${content.length} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²`);
    if (usage) {
      console.log(`ğŸ’° [Groq Vision] Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: $${usage.cost_usd.toFixed(6)}`);
    }

    return { analysis: content, usage };
  } catch (error: any) {
    console.error('âŒ [Groq Vision] ĞÑˆĞ¸Ğ±ĞºĞ°:', error.message);
    throw new Error(`Groq Vision failed: ${error.message}`);
  }
}

/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * PDF OPERATIONS (Pure JS via pdf-to-img)
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */

/**
 * ĞĞ½Ğ°Ğ»Ğ¸Ğ· PDF Ñ‡ĞµÑ€ĞµĞ· ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ² Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ
 * âœ… Pure JavaScript - NO native dependencies!
 */
export async function analyzePDF(
  pdfBuffer: Buffer,
  question: string,
  options: { page?: number } = {}
): Promise<VisionResponse> {
  try {
    console.log('ğŸ“„ [Groq PDF] ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ PDF â†’ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ (Pure JS)...');
    
    // Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ¸Ğ½Ğ°Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸
    const { convertPdfPageToImage } = await import('./pdfToImageService');
    
    // ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ PDF ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñƒ Ğ² Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ
    const imageBuffer = await convertPdfPageToImage(pdfBuffer, {
      pageNumber: (options.page || 0) + 1, // pdf-to-img uses 1-based indexing
      scale: 2,
      format: 'jpg',
    });
    
    console.log('ğŸ“„ [Groq PDF] ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Vision...');
    
    // ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ
    return await analyzeImage(imageBuffer, question, 'image/jpeg');
  } catch (error: any) {
    console.error('âŒ [Groq PDF] ĞÑˆĞ¸Ğ±ĞºĞ°:', error.message);
    throw new Error(`Groq PDF analysis failed: ${error.message}`);
  }
}

/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * WHISPER OPERATIONS (Groq Whisper Large v3 Turbo)
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */

export async function transcribeAudio(
  audioBuffer: Buffer,
  filename: string = 'recording.webm',
  mimeType: string = 'audio/webm'
): Promise<{ transcription: string; cost_usd: number }> {
  try {
    console.log('ğŸ¤ [Groq Whisper] Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾...');
    
    const audioFile = await toFile(audioBuffer, filename, { type: mimeType });

    const response = await groq.audio.transcriptions.create({
      file: audioFile,
      model: 'whisper-large-v3-turbo', // Ğ‘Ñ‹ÑÑ‚Ñ€ĞµĞµ Ğ¸ Ğ´ĞµÑˆĞµĞ²Ğ»Ğµ Ñ‡ĞµĞ¼ v3
      language: 'ru',
      response_format: 'json',
      temperature: 0.0,
    });

    // Groq Whisper: $0.04 per Ñ‡Ğ°Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾
    const audioSeconds = audioBuffer.length / (16000 * 2); // ĞŸÑ€Ğ¸Ğ±Ğ»Ğ¸Ğ·Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾
    const audioHours = audioSeconds / 3600;
    const cost_usd = audioHours * 0.04;

    console.log(`âœ… [Groq Whisper] Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ: "${response.text}"`);
    console.log(`ğŸ’° [Groq Whisper] Ğ¡Ñ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ: $${cost_usd.toFixed(6)}`);

    return {
      transcription: response.text,
      cost_usd
    };
  } catch (error: any) {
    console.error('âŒ [Groq Whisper] ĞÑˆĞ¸Ğ±ĞºĞ°:', error.message);
    throw new Error(`Groq Whisper failed: ${error.message}`);
  }
}

/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * UTILITY FUNCTIONS
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */

/**
 * ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Vision API
 * Groq Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹: 4MB base64, 20MB URL, 33 megapixels
 */
async function optimizeImageForVision(imageBuffer: Buffer): Promise<Buffer> {
  try {
    const MAX_BASE64_SIZE = 4 * 1024 * 1024; // 4MB
    const metadata = await sharp(imageBuffer).metadata();

    console.log(`ğŸ“Š [Image Optimize] Ğ˜ÑÑ…Ğ¾Ğ´Ğ½Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ: ${(imageBuffer.length / 1024).toFixed(2)}KB, ${metadata.width}x${metadata.height}px`);

    // Ğ•ÑĞ»Ğ¸ ÑƒĞ¶Ğµ Ğ¼Ğ°Ğ»ĞµĞ½ÑŒĞºĞ¾Ğµ, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ ĞºĞ°Ğº ĞµÑÑ‚ÑŒ
    if (imageBuffer.length < MAX_BASE64_SIZE * 0.8) {
      console.log('âœ… [Image Optimize] Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ ÑƒĞ¶Ğµ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾');
      return imageBuffer;
    }

    let optimized = sharp(imageBuffer);

    // Ğ£Ğ¼ĞµĞ½ÑŒÑˆĞ°ĞµĞ¼ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ ĞµÑĞ»Ğ¸ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğµ
    if (metadata.width! > 2048 || metadata.height! > 2048) {
      optimized = optimized.resize(2048, 2048, {
        fit: 'inside',
        withoutEnlargement: true
      });
    }

    // ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ² JPEG Ñ ĞºĞ¾Ğ¼Ğ¿Ñ€ĞµÑÑĞ¸ĞµĞ¹
    const compressed = await optimized
      .jpeg({ quality: 85, progressive: true })
      .toBuffer();

    console.log(`âœ… [Image Optimize] ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾: ${(compressed.length / 1024).toFixed(2)}KB`);

    if (compressed.length > MAX_BASE64_SIZE) {
      throw new Error(`Image too large after optimization: ${(compressed.length / 1024).toFixed(2)}KB`);
    }

    return compressed;
  } catch (error: any) {
    console.error('âŒ [Image Optimize] ĞÑˆĞ¸Ğ±ĞºĞ°:', error.message);
    throw error;
  }
}

/**
 * Ğ Ğ°ÑÑ‡Ñ‘Ñ‚ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹
 */
function calculateCost(
  operation: 'chat' | 'vision',
  inputTokens: number,
  outputTokens: number
): number {
  const PRICES = {
    chat: {
      // meta-llama/llama-3.3-70b-versatile
      input: 0.59,  // $ per 1M tokens
      output: 0.79
    },
    vision: {
      // meta-llama/llama-4-scout-17b-16e-instruct
      input: 0.11,
      output: 0.34
    }
  };

  const prices = PRICES[operation];
  const inputCost = (inputTokens / 1_000_000) * prices.input;
  const outputCost = (outputTokens / 1_000_000) * prices.output;

  return inputCost + outputCost;
}

/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * ĞœĞ•Ğ¢Ğ Ğ˜ĞšĞ˜ Ğ˜ Ğ¢Ğ Ğ•ĞšĞ˜ĞĞ“
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */

interface AIMetrics {
  operation_type: 'chat' | 'vision' | 'whisper';
  platform: 'main' | 'tripwire';
  provider: 'groq';
  model: string;
  input_tokens: number;
  output_tokens: number;
  cost_usd: number;
  user_id?: string;
  function_name: string;
  duration_ms: number;
}

/**
 * Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹ AI
 * TODO: Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ Ğ²Ğ°ÑˆĞµĞ¹ Ğ‘Ğ”
 */
export async function trackAIMetrics(metrics: AIMetrics): Promise<void> {
  try {
    console.log('ğŸ“Š [Metrics]', {
      operation: metrics.operation_type,
      cost: `$${metrics.cost_usd.toFixed(6)}`,
      tokens: `${metrics.input_tokens}+${metrics.output_tokens}`,
      duration: `${metrics.duration_ms}ms`
    });
    
    // TODO: Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ² Ğ‘Ğ”
    // await db.query('INSERT INTO ai_operations_metrics ...');
  } catch (error) {
    console.error('âŒ [Metrics] ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº:', error);
    // ĞĞµ Ğ±Ñ€Ğ¾ÑĞ°ĞµĞ¼ Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ - Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ½Ğµ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ»Ğ¾Ğ¼Ğ°Ñ‚ÑŒ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»
  }
}

export default {
  processChat,
  analyzeImage,
  analyzePDF,
  transcribeAudio,
  trackAIMetrics
};
